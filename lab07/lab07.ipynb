{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 1"
      ],
      "metadata": {
        "id": "RdgEhGl0gich"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "mFl16T_ogaiK"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import regexp_replace, col, month, upper, lit\n",
        "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Zamowienia\").getOrCreate()\n",
        "\n",
        "file_path = \"zamowienia.txt\"\n",
        "df = spark.read.option(\"header\", True).option(\"delimiter\", \";\").csv(file_path)\n",
        "df_cleaned = df \\\n",
        "    .withColumn(\"Sprzedawca\", regexp_replace(col(\"Sprzedawca\"), \"ä\", \"a\")) \\\n",
        "    .withColumn(\"Utarg\", regexp_replace(col(\"Utarg\"), \"[zł, ]\", \"\").cast(\"float\")) \\\n",
        "    .withColumn(\"idZamowienia\", col(\"idZamowienia\").cast(\"int\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 2"
      ],
      "metadata": {
        "id": "GrrPTPQmp6Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bucketed = df_cleaned.repartition(10, \"Kraj\")\n",
        "df_bucketed.createOrReplaceTempView(\"bucketed_data\")\n",
        "query_bucketed = \"SELECT Kraj, SUM(Utarg) as TotalRevenue FROM bucketed_data GROUP BY Kraj\"\n",
        "spark.sql(query_bucketed).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9q8NXejip9Bi",
        "outputId": "3548a758-abf6-4495-80c5-792507479243"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+\n",
            "|  Kraj|TotalRevenue|\n",
            "+------+------------+\n",
            "|Niemcy| 8.9499649E7|\n",
            "|Polska| 3.3333091E7|\n",
            "+------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_path_country = \"output/partitioned_by_country\"\n",
        "df_cleaned.write.partitionBy(\"Kraj\").csv(output_path_country, mode=\"overwrite\")\n",
        "\n",
        "output_path_seller = \"output/partitioned_by_seller\"\n",
        "df_cleaned.write.partitionBy(\"Sprzedawca\").csv(output_path_seller, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "TNQ7EtO2qe_2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "start_time_original = time.time()\n",
        "query_original = \"SELECT Kraj, SUM(Utarg) as TotalRevenue FROM original_data WHERE Kraj = 'Polska' GROUP BY Kraj\"\n",
        "result_original = spark.sql(query_original).collect()\n",
        "end_time_original = time.time()\n",
        "\n",
        "start_time_partitioned = time.time()\n",
        "query_partitioned = \"SELECT Kraj, SUM(Utarg) as TotalRevenue FROM partitioned_data WHERE Kraj = 'Polska' GROUP BY Kraj\"\n",
        "result_partitioned = spark.sql(query_partitioned).collect()\n",
        "end_time_partitioned = time.time()\n",
        "\n",
        "print(\"Wyniki na danych oryginalnych:\", result_original)\n",
        "print(\"Czas wykonania na danych oryginalnych:\", end_time_original - start_time_original, \"sekund\")\n",
        "\n",
        "print(\"Wyniki na danych partycjonowanych:\", result_partitioned)\n",
        "print(\"Czas wykonania na danych partycjonowanych:\", end_time_partitioned - start_time_partitioned, \"sekund\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXAdXEJOqitg",
        "outputId": "f33c48e8-2529-44d2-dd7d-158979cd5c44"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wyniki na danych oryginalnych: [Row(Kraj='Polska', TotalRevenue=33333091.0)]\n",
            "Czas wykonania na danych oryginalnych: 0.8237721920013428 sekund\n",
            "Wyniki na danych partycjonowanych: [Row(Kraj='Polska', TotalRevenue=33333091.0)]\n",
            "Czas wykonania na danych partycjonowanych: 0.5613882541656494 sekund\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 3"
      ],
      "metadata": {
        "id": "wZI_EJhJsc2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import month, upper, lit\n",
        "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
        "\n",
        "subset1 = df_cleaned.withColumn(\"month\", month(\"Data zamowienia\"))\n",
        "subset1.createOrReplaceTempView(\"subset1\")\n",
        "\n",
        "subset2 = df_cleaned.withColumn(\"Netto\", col(\"Utarg\") / 1.23)\n",
        "subset2.write.parquet(\"output/subset2.parquet\", mode=\"overwrite\")\n",
        "\n",
        "schema_subset3 = StructType([\n",
        "    StructField(\"Kraj\", StringType(), True),\n",
        "    StructField(\"Sprzedawca\", StringType(), True),\n",
        "    StructField(\"Data zamowienia\", StringType(), True),\n",
        "    StructField(\"idZamowienia\", IntegerType(), True),\n",
        "    StructField(\"Utarg\", FloatType(), True)\n",
        "])\n",
        "subset3 = df_cleaned.withColumn(\"Sprzedawca\", upper(col(\"Sprzedawca\")))\n",
        "subset3.write.csv(\"output/subset3.csv\", mode=\"overwrite\", header=False)\n",
        "\n",
        "subset4 = df_cleaned.withColumn(\"waluta\", lit(\"PLN\"))\n",
        "subset4.write.json(\"output/subset4.json\", mode=\"overwrite\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4c9tXdYso-1",
        "outputId": "81b53284-c8d3-4f7e-dd97-c47b2eedf4a0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+----------+--------+------------+------+\n",
            "|Data zamowienia|  Kraj|Sprzedawca|   Utarg|idZamowienia|waluta|\n",
            "+---------------+------+----------+--------+------------+------+\n",
            "|     16.07.2003|Polska|  Kowalski| 44000.0|       10248|   PLN|\n",
            "|     10.07.2003|Polska|  Sowiaski|186340.0|       10249|   PLN|\n",
            "|     12.07.2003|Niemcy|   Peacock|155260.0|       10250|   PLN|\n",
            "|     15.07.2003|Niemcy| Leverling| 65406.0|       10251|   PLN|\n",
            "|     11.07.2003|Niemcy|   Peacock|359790.0|       10252|   PLN|\n",
            "|     16.07.2003|Niemcy| Leverling|144480.0|       10253|   PLN|\n",
            "|     23.07.2003|Polska|  Kowalski| 55662.0|       10254|   PLN|\n",
            "|     15.07.2003|Polska|     Dudek|249050.0|       10255|   PLN|\n",
            "|     17.07.2003|Niemcy| Leverling| 51780.0|       10256|   PLN|\n",
            "|     22.07.2003|Niemcy|   Peacock|111990.0|       10257|   PLN|\n",
            "|     23.07.2003|Niemcy|   Davolio|161488.0|       10258|   PLN|\n",
            "|     25.07.2003|Niemcy|   Peacock| 10080.0|       10259|   PLN|\n",
            "|     29.07.2003|Niemcy|   Peacock|150465.0|       10260|   PLN|\n",
            "|     30.07.2003|Niemcy|   Peacock| 44800.0|       10261|   PLN|\n",
            "|     25.07.2003|Niemcy|  Callahan| 58400.0|       10262|   PLN|\n",
            "|     31.07.2003|Polska|     Dudek|187380.0|       10263|   PLN|\n",
            "|     23.08.2003|Polska|  Sowiaski| 69562.0|       10264|   PLN|\n",
            "|     12.08.2003|Niemcy|    Fuller|117600.0|       10265|   PLN|\n",
            "|     31.07.2003|Niemcy| Leverling| 34656.0|       10266|   PLN|\n",
            "|     06.08.2003|Niemcy|   Peacock|353660.0|       10267|   PLN|\n",
            "+---------------+------+----------+--------+------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}